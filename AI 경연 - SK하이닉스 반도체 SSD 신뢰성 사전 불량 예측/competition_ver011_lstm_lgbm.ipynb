{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in ./.local/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from xgboost) (1.11.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in ./.local/lib/python3.10/site-packages (from xgboost) (2.18.1)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lightgbm in ./.local/lib/python3.10/site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in ./.local/lib/python3.10/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from lightgbm) (1.11.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "!pip install xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "!pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data_dir = '/mnt/elice/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # Set the random seed for PyTorch on CPU and GPU\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # If using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Set the random seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set the random seed for Python's built-in random module\n",
    "    random.seed(seed)\n",
    "\n",
    "# Example usage:\n",
    "random_seed = 42  # Choose any integer value as the random seed\n",
    "set_seed(random_seed)\n",
    "\n",
    "# Now, the random seeds are set, and you can proceed with your PyTorch code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df: serial number, timestamp, X1, X2~18, Y\n",
    "train_df = pd.read_csv(os.path.join(data_dir, \"train.csv\"), index_col='Serial Number')\n",
    "# test_x: serial number, timestamp, X1, X2~18\n",
    "test_x = pd.read_csv(os.path.join(data_dir, \"test_x.csv\"), index_col='Serial Number')\n",
    "\n",
    "''' timestamp 열 형식 바꾸기 '''\n",
    "train_df['TIMESTAMP'] = pd.to_datetime(train_df['TIMESTAMP'])\n",
    "train_df['TIMESTAMP'] = train_df['TIMESTAMP'].map(lambda t: t.strftime('%Y-%m-%d %H:%M'))\n",
    "test_x['TIMESTAMP'] = pd.to_datetime(test_x['TIMESTAMP'])\n",
    "test_x['TIMESTAMP'] = test_x['TIMESTAMP'].map(lambda t: t.strftime('%Y-%m-%d %H:%M'))\n",
    "\n",
    "''' 컬럼 키 추출 '''\n",
    "serial_key = train_df.index.name\n",
    "date_time_key = list(train_df.columns)[0]\n",
    "feature_keys = list(train_df.columns)[2:-1]\n",
    "target_key = list(train_df.columns)[-1]\n",
    "\n",
    "# train_x: serial number, timestamp, X1, X2~18\n",
    "train_x = train_df.drop(columns='Y')\n",
    "# train_y: serial_number, Y\n",
    "train_y = pd.read_csv(os.path.join(data_dir, \"train_y.csv\"), index_col='Serial Number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 장비 이름을 나타내는 X1 변수를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.drop(columns='X1', inplace=True)\n",
    "test_x.drop(columns='X1', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `StandardScaler` 를 활용해 표준화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_x[feature_keys] = scaler.fit_transform(train_x[feature_keys])\n",
    "test_x[feature_keys] = scaler.transform(test_x[feature_keys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial Number를 기준으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 index가 같은 컬럼 별로 분리해서 리스트에 저장\n",
    "# group: (그룹 이름, 그룹 데이터프레임) => group[1]: 그룹 데이터프레임\n",
    "train_x_by_serial = [group[1] for group in train_x.groupby(train_x.index)]\n",
    "test_x_by_serial = [group[1] for group in test_x.groupby(test_x.index)]\n",
    "\n",
    "# TIMESTAMP 값을 기준으로 정렬\n",
    "train_x_by_serial = [group.sort_values('TIMESTAMP') for group in train_x_by_serial]\n",
    "test_x_by_serial = [group.sort_values('TIMESTAMP') for group in test_x_by_serial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serial Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-02-09 08:01</td>\n",
       "      <td>0.237359</td>\n",
       "      <td>0.176644</td>\n",
       "      <td>1.060111</td>\n",
       "      <td>1.067976</td>\n",
       "      <td>1.258588</td>\n",
       "      <td>-0.079582</td>\n",
       "      <td>0.845695</td>\n",
       "      <td>0.629975</td>\n",
       "      <td>0.059574</td>\n",
       "      <td>-1.734490</td>\n",
       "      <td>-0.465737</td>\n",
       "      <td>-0.012637</td>\n",
       "      <td>-0.035175</td>\n",
       "      <td>-0.464819</td>\n",
       "      <td>-0.010677</td>\n",
       "      <td>-0.011952</td>\n",
       "      <td>-0.013366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-02-10 08:16</td>\n",
       "      <td>0.237359</td>\n",
       "      <td>0.176644</td>\n",
       "      <td>1.060111</td>\n",
       "      <td>1.067976</td>\n",
       "      <td>1.258588</td>\n",
       "      <td>-0.079582</td>\n",
       "      <td>0.849884</td>\n",
       "      <td>0.633251</td>\n",
       "      <td>0.059664</td>\n",
       "      <td>-1.684896</td>\n",
       "      <td>-0.410967</td>\n",
       "      <td>-0.012621</td>\n",
       "      <td>-0.035175</td>\n",
       "      <td>-0.409868</td>\n",
       "      <td>-0.010677</td>\n",
       "      <td>-0.011952</td>\n",
       "      <td>-0.012643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-02-11 08:31</td>\n",
       "      <td>0.237359</td>\n",
       "      <td>0.176644</td>\n",
       "      <td>1.060111</td>\n",
       "      <td>1.067976</td>\n",
       "      <td>1.258588</td>\n",
       "      <td>-0.079582</td>\n",
       "      <td>0.854143</td>\n",
       "      <td>0.636589</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>-1.635302</td>\n",
       "      <td>-0.315119</td>\n",
       "      <td>-0.012613</td>\n",
       "      <td>-0.035175</td>\n",
       "      <td>-0.313703</td>\n",
       "      <td>-0.010677</td>\n",
       "      <td>-0.011952</td>\n",
       "      <td>-0.012282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-02-12 08:46</td>\n",
       "      <td>0.237359</td>\n",
       "      <td>0.176644</td>\n",
       "      <td>1.060111</td>\n",
       "      <td>1.067976</td>\n",
       "      <td>1.258588</td>\n",
       "      <td>-0.079582</td>\n",
       "      <td>0.858803</td>\n",
       "      <td>0.640521</td>\n",
       "      <td>0.060115</td>\n",
       "      <td>-1.583642</td>\n",
       "      <td>-0.219271</td>\n",
       "      <td>-0.012589</td>\n",
       "      <td>-0.035175</td>\n",
       "      <td>-0.217539</td>\n",
       "      <td>-0.010677</td>\n",
       "      <td>-0.011952</td>\n",
       "      <td>-0.011199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-02-13 09:01</td>\n",
       "      <td>0.237359</td>\n",
       "      <td>0.176644</td>\n",
       "      <td>1.060111</td>\n",
       "      <td>1.067976</td>\n",
       "      <td>1.258588</td>\n",
       "      <td>-0.079582</td>\n",
       "      <td>0.863227</td>\n",
       "      <td>0.644140</td>\n",
       "      <td>0.060295</td>\n",
       "      <td>-1.534048</td>\n",
       "      <td>-0.127987</td>\n",
       "      <td>-0.012589</td>\n",
       "      <td>-0.035175</td>\n",
       "      <td>-0.125954</td>\n",
       "      <td>-0.010677</td>\n",
       "      <td>-0.011952</td>\n",
       "      <td>-0.011199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-04-14 00:01</td>\n",
       "      <td>0.237359</td>\n",
       "      <td>0.176644</td>\n",
       "      <td>1.407310</td>\n",
       "      <td>1.067976</td>\n",
       "      <td>1.258588</td>\n",
       "      <td>-0.079582</td>\n",
       "      <td>1.133848</td>\n",
       "      <td>0.867393</td>\n",
       "      <td>0.078570</td>\n",
       "      <td>1.480844</td>\n",
       "      <td>4.029984</td>\n",
       "      <td>-0.012373</td>\n",
       "      <td>-0.035175</td>\n",
       "      <td>4.045745</td>\n",
       "      <td>-0.010677</td>\n",
       "      <td>-0.011952</td>\n",
       "      <td>-0.001446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-04-15 00:16</td>\n",
       "      <td>0.237359</td>\n",
       "      <td>0.176644</td>\n",
       "      <td>1.407310</td>\n",
       "      <td>1.067976</td>\n",
       "      <td>1.258588</td>\n",
       "      <td>-0.079582</td>\n",
       "      <td>1.138296</td>\n",
       "      <td>0.870981</td>\n",
       "      <td>0.078840</td>\n",
       "      <td>1.530438</td>\n",
       "      <td>4.198859</td>\n",
       "      <td>-0.012345</td>\n",
       "      <td>-0.035175</td>\n",
       "      <td>4.215177</td>\n",
       "      <td>-0.010677</td>\n",
       "      <td>-0.011952</td>\n",
       "      <td>-0.000362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-04-16 00:31</td>\n",
       "      <td>0.237359</td>\n",
       "      <td>0.176644</td>\n",
       "      <td>1.407310</td>\n",
       "      <td>1.067976</td>\n",
       "      <td>1.258588</td>\n",
       "      <td>-0.079582</td>\n",
       "      <td>1.142649</td>\n",
       "      <td>0.874445</td>\n",
       "      <td>0.079110</td>\n",
       "      <td>1.580032</td>\n",
       "      <td>4.317527</td>\n",
       "      <td>-0.012345</td>\n",
       "      <td>-0.035175</td>\n",
       "      <td>4.334238</td>\n",
       "      <td>-0.010677</td>\n",
       "      <td>-0.011952</td>\n",
       "      <td>-0.000362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-04-17 00:46</td>\n",
       "      <td>0.237359</td>\n",
       "      <td>0.176644</td>\n",
       "      <td>1.407310</td>\n",
       "      <td>1.067976</td>\n",
       "      <td>1.258588</td>\n",
       "      <td>-0.079582</td>\n",
       "      <td>1.147262</td>\n",
       "      <td>0.878283</td>\n",
       "      <td>0.079335</td>\n",
       "      <td>1.631692</td>\n",
       "      <td>4.490966</td>\n",
       "      <td>-0.012337</td>\n",
       "      <td>-0.035175</td>\n",
       "      <td>4.508249</td>\n",
       "      <td>-0.010677</td>\n",
       "      <td>-0.011952</td>\n",
       "      <td>-0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-04-18 01:01</td>\n",
       "      <td>0.237359</td>\n",
       "      <td>0.176644</td>\n",
       "      <td>1.407310</td>\n",
       "      <td>1.067976</td>\n",
       "      <td>1.258588</td>\n",
       "      <td>-0.079582</td>\n",
       "      <td>1.151803</td>\n",
       "      <td>0.881965</td>\n",
       "      <td>0.079470</td>\n",
       "      <td>1.681286</td>\n",
       "      <td>4.682662</td>\n",
       "      <td>-0.012337</td>\n",
       "      <td>-0.035175</td>\n",
       "      <td>4.700578</td>\n",
       "      <td>-0.010677</td>\n",
       "      <td>-0.011952</td>\n",
       "      <td>-0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      TIMESTAMP        X2        X3        X4        X5  \\\n",
       "Serial Number                                                             \n",
       "48             2020-02-09 08:01  0.237359  0.176644  1.060111  1.067976   \n",
       "48             2020-02-10 08:16  0.237359  0.176644  1.060111  1.067976   \n",
       "48             2020-02-11 08:31  0.237359  0.176644  1.060111  1.067976   \n",
       "48             2020-02-12 08:46  0.237359  0.176644  1.060111  1.067976   \n",
       "48             2020-02-13 09:01  0.237359  0.176644  1.060111  1.067976   \n",
       "...                         ...       ...       ...       ...       ...   \n",
       "48             2020-04-14 00:01  0.237359  0.176644  1.407310  1.067976   \n",
       "48             2020-04-15 00:16  0.237359  0.176644  1.407310  1.067976   \n",
       "48             2020-04-16 00:31  0.237359  0.176644  1.407310  1.067976   \n",
       "48             2020-04-17 00:46  0.237359  0.176644  1.407310  1.067976   \n",
       "48             2020-04-18 01:01  0.237359  0.176644  1.407310  1.067976   \n",
       "\n",
       "                     X6        X7        X8        X9       X10       X11  \\\n",
       "Serial Number                                                               \n",
       "48             1.258588 -0.079582  0.845695  0.629975  0.059574 -1.734490   \n",
       "48             1.258588 -0.079582  0.849884  0.633251  0.059664 -1.684896   \n",
       "48             1.258588 -0.079582  0.854143  0.636589  0.059844 -1.635302   \n",
       "48             1.258588 -0.079582  0.858803  0.640521  0.060115 -1.583642   \n",
       "48             1.258588 -0.079582  0.863227  0.644140  0.060295 -1.534048   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "48             1.258588 -0.079582  1.133848  0.867393  0.078570  1.480844   \n",
       "48             1.258588 -0.079582  1.138296  0.870981  0.078840  1.530438   \n",
       "48             1.258588 -0.079582  1.142649  0.874445  0.079110  1.580032   \n",
       "48             1.258588 -0.079582  1.147262  0.878283  0.079335  1.631692   \n",
       "48             1.258588 -0.079582  1.151803  0.881965  0.079470  1.681286   \n",
       "\n",
       "                    X12       X13       X14       X15       X16       X17  \\\n",
       "Serial Number                                                               \n",
       "48            -0.465737 -0.012637 -0.035175 -0.464819 -0.010677 -0.011952   \n",
       "48            -0.410967 -0.012621 -0.035175 -0.409868 -0.010677 -0.011952   \n",
       "48            -0.315119 -0.012613 -0.035175 -0.313703 -0.010677 -0.011952   \n",
       "48            -0.219271 -0.012589 -0.035175 -0.217539 -0.010677 -0.011952   \n",
       "48            -0.127987 -0.012589 -0.035175 -0.125954 -0.010677 -0.011952   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "48             4.029984 -0.012373 -0.035175  4.045745 -0.010677 -0.011952   \n",
       "48             4.198859 -0.012345 -0.035175  4.215177 -0.010677 -0.011952   \n",
       "48             4.317527 -0.012345 -0.035175  4.334238 -0.010677 -0.011952   \n",
       "48             4.490966 -0.012337 -0.035175  4.508249 -0.010677 -0.011952   \n",
       "48             4.682662 -0.012337 -0.035175  4.700578 -0.010677 -0.011952   \n",
       "\n",
       "                    X18  \n",
       "Serial Number            \n",
       "48            -0.013366  \n",
       "48            -0.012643  \n",
       "48            -0.012282  \n",
       "48            -0.011199  \n",
       "48            -0.011199  \n",
       "...                 ...  \n",
       "48            -0.001446  \n",
       "48            -0.000362  \n",
       "48            -0.000362  \n",
       "48            -0.000001  \n",
       "48            -0.000001  \n",
       "\n",
       "[67 rows x 18 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_by_serial[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, valid 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(Xs, ys, test_ratio=0.2):\n",
    "    ''' 각 (x, y) 쌍을 label 별로 딕셔너리에 저장 '''\n",
    "    data_per_label = {}\n",
    "\n",
    "    for x, y in zip(Xs, ys):\n",
    "        label = y\n",
    "        if label not in data_per_label:\n",
    "            data_per_label[label] = []\n",
    "        # key: label, value: 해당 label에 해당하는 (x, y) 쌍의 리스트\n",
    "        data_per_label[label].append((x, y))\n",
    "\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    for label in data_per_label:\n",
    "        # label에 해당하는 데이터 가져온다\n",
    "        data = data_per_label[label]\n",
    "        # 테스트 데이터의 개수\n",
    "        n_test = int(len(data) * test_ratio)\n",
    "        test += data[:n_test]\n",
    "        train += data[n_test:]\n",
    "\n",
    "    X_train, y_train = zip(*train)\n",
    "    X_test, y_test = zip(*test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data의 개수 : 6618\n",
      "Validation Data의 개수 : 1654\n",
      "Test Data의 개수 : 2069\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_x_by_serial, train_y['Y'], test_ratio=0.2)\n",
    "\n",
    "# X data에서 Timestamp를 제거합니다.\n",
    "X_train = [x.drop(columns='TIMESTAMP') for x in X_train]\n",
    "X_val = [x.drop(columns='TIMESTAMP') for x in X_val]\n",
    "X_test = [x.drop(columns='TIMESTAMP') for x in test_x_by_serial]\n",
    "\n",
    "print(\"Train Data의 개수 :\", len(X_train))\n",
    "print(\"Validation Data의 개수 :\", len(X_val))\n",
    "print(\"Test Data의 개수 :\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝 모델에 적용하기 위해 학습, 검증, 테스트용 데이터를 각각 하나의 numpy array로 합칩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_data(data, series_length):\n",
    "    # X2~18열에 해당하는 시계열 데이터 값만 추출\n",
    "    data_features = [x[feature_keys] for x in data]\n",
    "    len_data = len(data_features)\n",
    "    length_aligned_X = []\n",
    "    for x in data_features:\n",
    "        # 시계열 데이터 길이가 series_length 이상이면 > 뒷부분 잘라냄\n",
    "        if len(x) >= series_length:\n",
    "            length_aligned_X.append(x[:series_length])\n",
    "        # 시계열 데이터 길이가 series_length보다 작으면 > 마지막 행을 반복하여 길이를 맞춤\n",
    "        else:\n",
    "            length_aligned_X.append(x.append([x.iloc[-1]] * (series_length - len(x))))\n",
    "    return np.array(length_aligned_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_length = 67\n",
    "\n",
    "X_train = align_data(X_train, series_length)\n",
    "X_val = align_data(X_val, series_length)\n",
    "X_test = align_data(X_test, series_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6618, 67, 17)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[227], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m LGBMClassifier(num_leaves \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m,\n\u001b[1;32m      2\u001b[0m                        min_child_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m,\n\u001b[1;32m      3\u001b[0m                        colsample_bytree \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m,\n\u001b[1;32m      4\u001b[0m                        learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m,\n\u001b[1;32m      5\u001b[0m                        n_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m      6\u001b[0m                        random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 검증 데이터에 대한 예측\u001b[39;00m\n\u001b[1;32m     10\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:1284\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1282\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1284\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:865\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    862\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [metric \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (pd_DataFrame, dt_DataTable)):\n\u001b[0;32m--> 865\u001b[0m     _X, _y \u001b[38;5;241m=\u001b[39m \u001b[43m_LGBMCheckXY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         sample_weight \u001b[38;5;241m=\u001b[39m _LGBMCheckSampleWeight(sample_weight, _X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    913\u001b[0m     )\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m     )\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    921\u001b[0m     _assert_all_finite(\n\u001b[1;32m    922\u001b[0m         array,\n\u001b[1;32m    923\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    924\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    925\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    926\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(num_leaves = 40,\n",
    "                       min_child_samples = 60,\n",
    "                       colsample_bytree = 0.8,\n",
    "                       learning_rate = 0.05,\n",
    "                       n_estimators = 500,\n",
    "                       random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 데이터에 대한 예측\n",
    "y_val_pred = model.predict(X_val)\n",
    "# 검증 데이터에 대한 F1 점수 계산\n",
    "f1_val = f1_score(y_val, y_val_pred, average='macro')\n",
    "print('Validation F1 score = %.3f' % f1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lstm 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./.local/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: triton==2.1.0 in ./.local/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train의 차원을 변경합니다.\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "# permute를 사용하여 차원을 (seq_length, batch_size, input_size)로 변환합니다.\n",
    "X_train_tensor = X_train_tensor.permute(1, 0, 2)  # (64, 1139, 1) -> (1139, 64, 1)\n",
    "\n",
    "# 데이터와 레이블을 Tensor로 변환\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)  # y_val은 클래스 레이블이므로 long 타입\n",
    "\n",
    "X_val_tensor = X_val_tensor.permute(1, 0, 2)  # (batch_size, seq_length, 1) -> (seq_length, batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LabeledNumpyArrayDataset(Dataset):\n",
    "    def __init__(self, numpy_data, numpy_labels, transform=None):\n",
    "        self.data = numpy_data\n",
    "        self.labels = numpy_labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = LabeledNumpyArrayDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_dataset = LabeledNumpyArrayDataset(X_val_tensor, y_val_tensor)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, device):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        batch_size = data.size(0)\n",
    "\n",
    "        h0 = torch.zeros(self.layer_dim, batch_size, self.hidden_dim).to(self.device)\n",
    "        c0 = torch.zeros(self.layer_dim, batch_size, self.hidden_dim).to(self.device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(data, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # 현재 out의 차원은 (batch_size, seq_length, hidden_size)입니다.\n",
    "        # 이를 fully connected layer에 fit하게 차원을 변경(batch_size, hidden_size)해주어야 합니다.\n",
    "        # fc layer를 통해 (batch_size, output_dim)로 차원을 변경해줍니다.\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 10\n",
    "hidden_dim = 4\n",
    "layer_dim = 1\n",
    "output_dim = 2\n",
    "feature_size = X_train.shape[2]\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = LSTMModel(feature_size, hidden_dim, layer_dim, output_dim, 0.5, device)\n",
    "model.apply(init_weights)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 0.00002)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    for i, (text, labels) in enumerate(train_dataloader):\n",
    "    \n",
    "        text = text.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(text)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.4640\n"
     ]
    }
   ],
   "source": [
    "# 1. 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "# 2. 모든 배치에서 예측을 저장할 리스트\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# 3. 검증 데이터에 대해 예측 수행\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_dataloader:  # valid_dataloader는 검증 데이터 로더\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 모델 예측\n",
    "        logits = model(inputs)\n",
    "        _, preds = torch.max(logits, 1)  # 가장 높은 확률을 가진 클래스 선택\n",
    "\n",
    "        # 결과를 리스트에 저장\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 4. F1 점수 계산\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')  # 'weighted'는 클래스 불균형을 고려한 평균 방식\n",
    "\n",
    "print(f'F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09569840502658289\n",
      "Y    0.146518\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "# permute를 사용하여 차원을 (seq_length, batch_size, input_size)로 변환합니다.\n",
    "#X_test_tensor = X_test_tensor.permute(1, 0, 2)  \n",
    "\n",
    "\n",
    "# 2. 모델 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "# 3. 예측 수행\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = X_test_tensor.to(device)\n",
    "    logits = model(X_test_tensor)\n",
    "    _, y_test_pred = torch.max(logits, 1)  # 가장 높은 확률을 가진 클래스 선택\n",
    "\n",
    "# 4. 예측 결과 후처리\n",
    "submission = pd.read_csv(os.path.join(data_dir, \"test_y.csv\"), index_col='Serial Number')\n",
    "submission[\"Y\"] = y_test_pred.cpu().numpy()  # 예측 결과를 넘파이 배열로 변환하여 저장\n",
    "submission.to_csv(\"submission.csv\", index_label='Serial Number')\n",
    "submission\n",
    "# 예측 결과 중 1의 비율을 계산하고, 학습용 데이터의 비율과 비교합니다.\n",
    "print(submission[\"Y\"].mean())\n",
    "print(train_y.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제출\n",
    "\n",
    "우측 상단의 제출 버튼을 눌러, `competition.ipynb` 파일과 `submission.csv` 파일을 제출합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
